# Limitations, Risks, and Trade-offs

This document outlines the known limitations and trade-offs of the data cleaning approach.

1.  **LLM Hallucination and Accuracy Risk**:
    *   **Limitation**: Despite setting a low temperature, there is always a non-zero risk that the LLM could "hallucinate" or provide an incorrect classification, especially for truly ambiguous or novel device types not covered in its training data. The confidence score it provides is generated by the model itself and is not a statistically rigorous guarantee of accuracy.
    *   **Trade-off**: We traded the full automation of a pure-AI approach for the reliability of a human-in-the-loop process. The manual step of verifying and integrating LLM responses mitigates this risk but reduces the overall speed and scalability of the solution.

2.  **Lack of External Context and Ground Truth**:
    *   **Limitation**: The entire process operates in a closed-world environment, relying only on the data within the provided CSV. It cannot connect to external systems (like a live CMDB, network monitoring tools, or Active Directory) to get "ground truth" data. For example, it cannot verify if an owner email is actually valid or if a device is truly online at a given IP.
    *   **Trade-off**: This makes the solution self-contained and highly reproducible, but it sacrifices a significant layer of potential validation and enrichment. A real-world system would ideally integrate with such external sources for higher accuracy.

3.  **Scalability of Manual LLM Intervention**:
    *   **Limitation**: The current workflow of identifying ambiguous cases, manually prompting an LLM, and integrating the results into the script is effective for a small number of exceptions. However, this process is not scalable. If a new dataset contains hundreds or thousands of new, ambiguous `device_type` strings, the manual bottleneck would render the solution impractical.
    *   **Trade-off**: We prioritized a clear, auditable, and reproducible workflow for this specific assignment over building a fully automated, scalable pipeline. A production-grade system would require a more advanced setup, perhaps involving a fine-tuned model, automated prompt engineering, and a database for storing and retrieving LLM-classified results without modifying the script for every new case.

4.  **Simplistic FQDN Consistency Check**:
    *   **Limitation**: The check for `fqdn_consistent` is a simple `fqdn.startswith(hostname)`. This doesn't account for more complex (but valid) scenarios like split-horizon DNS where internal and external FQDNs might differ, or cases where the hostname is a short alias and the FQDN is the full canonical name.
    *   **Trade-off**: A simple, fast check was chosen over a more complex and potentially slow DNS resolution or logic-based comparison, which would have diminishing returns for this specific dataset.
